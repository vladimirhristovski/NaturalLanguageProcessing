{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78336518-f7de-4eae-8fe2-d743139e694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from evaluate import load\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import os\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc1b5e6-c909-4658-8892-7e7977f73355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9d707966ce481f83d6f3b88c969769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login(token=os.getenv('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c0ad06-3592-482f-a20d-0f74f90a5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('yelp_parallel/test_en_parallel.txt', sep='\\t')\n",
    "data.columns = ['Style1', 'Style2']\n",
    "data = data[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd41f05-b6f3-4c15-bd55-78815048a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_negative = data['Style1'].values.tolist()\n",
    "sentences_positive = data['Style2'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc08dd3-3ae6-46db-913c-28b49e5b3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "bitsandbytes_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.float16,\n",
    "                                         bnb_4bit_quant_type='nf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9d080d-625d-441f-b5b2-068c68499a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa9117aaf1744d1a138bff2f2666694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             quantization_config=bitsandbytes_config,\n",
    "                                             device_map='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0e2f79-d277-46b6-b659-71ad8d7cbfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b43e33a8704caabc2e59052bb30b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d3b55760034228984eedb969399619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b4a25c69d94f0aa02173e69a0d15f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bleu = load('bleu')\n",
    "bertscore = load('bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e2e318-5574-45d3-be8a-56090eec742c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ever since joes has changed hands it's just gotten worse and worse.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zero-shot\n",
    "sample_sentence = sentences_negative[0]\n",
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4c83ce-340c-463c-afb3-3c274720618c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Transform the following negative sentence to positive: ever since joes has changed hands it's just gotten worse and worse.\\nPositive: \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'Transform the following negative sentence to positive: {sample_sentence}\\nPositive: '\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d74fefe-c2ee-4ded-b5ca-7084838869ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,  4103,   689,   278,  1494,  8178, 10541,   304,  6374, 29901,\n",
       "          3926,  1951,  2958,   267,   756,  3939,  6567,   372, 29915, 29879,\n",
       "           925,  2355,   841, 15029,   322, 15029, 29889,    13,  9135,  3321,\n",
       "         29901, 29871]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d076b214-daf7-47fa-ae69-adbc21cb8f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  4103,   689,   278,  1494,  8178, 10541,   304,  6374, 29901,\n",
       "          3926,  1951,  2958,   267,   756,  3939,  6567,   372, 29915, 29879,\n",
       "           925,  2355,   841, 15029,   322, 15029, 29889,    13,  9135,  3321,\n",
       "         29901, 29871, 25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285,\n",
       "         25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285,\n",
       "         25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285,\n",
       "         25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285,\n",
       "         25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285, 25285,\n",
       "         25285, 25285]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b390c5be-a7b3-4383-82d2-420434c9d8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Transform the following negative sentence to positive: ever since joes has changed hands it's just gotten worse and worse.\\nPositive: ................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04fb86ce-a0bd-429a-a2e1-f1ebb24e29a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_0 = []\n",
    "references_0 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17dc5c1b-cdc7-435f-8c32-7b1487aea29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    prompt = f'Transform the following negative sentence to positive: {sentences_negative[i]}\\nPositive: '\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    pred = output.split('Positive:')[-1].strip() if 'Positive:' in output else output.split('\\n')[-1].strip()\n",
    "    predictions_0.append(pred)\n",
    "    references_0.append(sentences_positive[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "695722e5-95b9-413f-ae2c-ed61ea788596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.006770613426183067,\n",
       " 'precisions': [0.02568397543271915,\n",
       "  0.010662177328843996,\n",
       "  0.0045121263395375075,\n",
       "  0.0017006802721088435],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 17.91,\n",
       " 'translation_length': 1791,\n",
       " 'reference_length': 100}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=predictions_0, references=[[ref] for ref in references_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a340b6cd-ce84-4e49-81ec-872a3228d340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': [0.48212531208992004,\n",
       "  0.18001851439476013,\n",
       "  0.0,\n",
       "  0.1839916706085205,\n",
       "  0.7004492282867432,\n",
       "  0.3902304172515869,\n",
       "  0.3722982704639435,\n",
       "  0.39336657524108887,\n",
       "  0.6014003753662109,\n",
       "  0.5318043828010559],\n",
       " 'recall': [0.5934234857559204,\n",
       "  0.3732936382293701,\n",
       "  0.0,\n",
       "  0.3349146246910095,\n",
       "  0.8469482660293579,\n",
       "  0.5931626558303833,\n",
       "  0.6140822768211365,\n",
       "  0.5618292689323425,\n",
       "  0.6054982542991638,\n",
       "  0.5594109296798706],\n",
       " 'f1': [0.5320158004760742,\n",
       "  0.24290001392364502,\n",
       "  0.0,\n",
       "  0.23750531673431396,\n",
       "  0.7667638659477234,\n",
       "  0.4707580506801605,\n",
       "  0.4635569155216217,\n",
       "  0.46274250745773315,\n",
       "  0.603442370891571,\n",
       "  0.5452584028244019],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=predictions_0, references=references_0, model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce50d30f-cadb-496a-bc6b-10d7f612d4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative: the food was terrible\\nPositive: the food was excellent'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-shot\n",
    "example = 'Negative: the food was terrible\\nPositive: the food was excellent'\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0800201-ef8b-4cb9-9ea6-4b41ad52db20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there is definitely not enough room in that part of the venue.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = sentences_negative[1]\n",
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "196be1e6-d118-4e09-88d7-e598c99a0742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: there is definitely not enough room in that part of the venue.\\nPositive: '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'{example}\\n\\nNegative: {sample_sentence}\\nPositive: '\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0499c614-100c-4ce7-b996-4baef246e584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: there is definitely not enough room in that part of the venue.\\nPositive: \\n\\nNegative: \\n\\nNegative: \\n\\nNegative: \\n\\nNegative: \\n\\nNegative: \\n\\nNegative: \\n\\nNegative: \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d500c68-007b-4644-8f6b-2db807cbb0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = []\n",
    "references_1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f54f8ee8-1845-4217-a021-2d3769af2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    prompt = f'{example}\\n\\nNegative: {sentences_negative[i]}\\nPositive: '\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    pred = output.split('Positive:')[-1].strip() if 'Positive:' in output else output.split('\\n')[-1].strip()\n",
    "    predictions_1.append(pred)\n",
    "    references_1.append(sentences_positive[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7585a1e-2b62-4758-9628-bf2161f979fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [0.1927710843373494,\n",
       "  0.10526315789473684,\n",
       "  0.02857142857142857,\n",
       "  0.0],\n",
       " 'brevity_penalty': 0.8147945551343462,\n",
       " 'length_ratio': 0.83,\n",
       " 'translation_length': 83,\n",
       " 'reference_length': 100}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=predictions_1, references=[[ref] for ref in references_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9c4dd89-fe02-47ce-85dc-b45d6e79fc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': [0.0,\n",
       "  0.48055315017700195,\n",
       "  0.0,\n",
       "  0.3161439001560211,\n",
       "  0.7941712737083435,\n",
       "  0.0,\n",
       "  0.5118494629859924,\n",
       "  0.25768721103668213,\n",
       "  0.32971903681755066,\n",
       "  0.2829959988594055],\n",
       " 'recall': [0.0,\n",
       "  0.5796743631362915,\n",
       "  0.0,\n",
       "  0.34851500391960144,\n",
       "  0.7376935482025146,\n",
       "  0.0,\n",
       "  0.6840810775756836,\n",
       "  0.2824844717979431,\n",
       "  0.3182152807712555,\n",
       "  0.3795325756072998],\n",
       " 'f1': [0.0,\n",
       "  0.5254802703857422,\n",
       "  0.0,\n",
       "  0.33154115080833435,\n",
       "  0.7648912072181702,\n",
       "  0.0,\n",
       "  0.5855633616447449,\n",
       "  0.26951664686203003,\n",
       "  0.32386505603790283,\n",
       "  0.3242311477661133],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=predictions_1, references=references_1, model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2599d72c-a3f9-4e6b-a756-c313a437bda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: awful service\\nPositive: great service\\n\\nNegative: worst experience\\nPositive: best experience\\n\\nNegative: not good at all\\nPositive: very good\\n\\nNegative: disappointing meal\\nPositive: amazing meal'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Five-shot\n",
    "examples_5 = 'Negative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: awful service\\nPositive: great service\\n\\nNegative: worst experience\\nPositive: best experience\\n\\nNegative: not good at all\\nPositive: very good\\n\\nNegative: disappointing meal\\nPositive: amazing meal'\n",
    "examples_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f8924ae-88bb-47c6-bae2-3f0bce6b5d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'so basically tasted watered down.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = sentences_negative[2]\n",
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd4700b4-e202-462b-b559-ec6c62bce28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: awful service\\nPositive: great service\\n\\nNegative: worst experience\\nPositive: best experience\\n\\nNegative: not good at all\\nPositive: very good\\n\\nNegative: disappointing meal\\nPositive: amazing meal\\n\\nNegative: so basically tasted watered down.\\nPositive: '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'{examples_5}\\n\\nNegative: {sample_sentence}\\nPositive: '\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4984be19-3608-419d-8228-e3201467da42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: awful service\\nPositive: great service\\n\\nNegative: worst experience\\nPositive: best experience\\n\\nNegative: not good at all\\nPositive: very good\\n\\nNegative: disappointing meal\\nPositive: amazing meal\\n\\nNegative: so basically tasted watered down.\\nPositive: \\n\\nNegative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: awful service\\nPositive: great service\\n\\nNegative: worst experience\\nPositive: best experience\\n\\nNeg'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1801f5e9-fd8c-43c5-8abf-bcd46187c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_5 = []\n",
    "references_5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78e62ecf-0535-4ecc-8279-e3ff60cdfafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    prompt = f'{examples_5}\\n\\nNegative: {sentences_negative[i]}\\nPositive: '\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    pred = output.split('Positive:')[-1].strip() if 'Positive:' in output else output.split('\\n')[-1].strip()\n",
    "    predictions_5.append(pred)\n",
    "    references_5.append(sentences_positive[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d632b12-351f-4aa5-a1cb-31580ec458df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [0.23684210526315788, 0.06451612903225806, 0.0, 0.0],\n",
       " 'brevity_penalty': 0.19562045574649367,\n",
       " 'length_ratio': 0.38,\n",
       " 'translation_length': 38,\n",
       " 'reference_length': 100}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=predictions_5, references=[[ref] for ref in references_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "702343d2-d500-431d-9bd8-1f6a4d4b69d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': [0.29588770866394043,\n",
       "  0.2990191578865051,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.525473952293396,\n",
       "  0.30622485280036926,\n",
       "  0.4155178964138031,\n",
       "  0.0,\n",
       "  0.47124630212783813,\n",
       "  0.40099745988845825],\n",
       " 'recall': [0.33613187074661255,\n",
       "  0.36854127049446106,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7323873043060303,\n",
       "  0.412492573261261,\n",
       "  0.5519180297851562,\n",
       "  0.0,\n",
       "  0.36022430658340454,\n",
       "  0.45194560289382935],\n",
       " 'f1': [0.3147284984588623,\n",
       "  0.3301600515842438,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6119123697280884,\n",
       "  0.3515024483203888,\n",
       "  0.47410231828689575,\n",
       "  0.0,\n",
       "  0.4083231985569,\n",
       "  0.42494991421699524],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=predictions_5, references=references_5, model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db988ae9-00be-4112-affe-037214b3dcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: awful service\\nPositive: great service\\n\\nNegative: worst experience\\nPositive: best experience\\n\\nNegative: not good at all\\nPositive: very good\\n\\nNegative: disappointing meal\\nPositive: amazing meal\\n\\nNegative: horrible place\\nPositive: wonderful place\\n\\nNegative: never coming back\\nPositive: definitely coming back\\n\\nNegative: waste of money\\nPositive: worth the money\\n\\nNegative: rude staff\\nPositive: friendly staff\\n\\nNegative: cold food\\nPositive: hot food'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ten-shot\n",
    "examples_10 = 'Negative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: awful service\\nPositive: great service\\n\\nNegative: worst experience\\nPositive: best experience\\n\\nNegative: not good at all\\nPositive: very good\\n\\nNegative: disappointing meal\\nPositive: amazing meal\\n\\nNegative: horrible place\\nPositive: wonderful place\\n\\nNegative: never coming back\\nPositive: definitely coming back\\n\\nNegative: waste of money\\nPositive: worth the money\\n\\nNegative: rude staff\\nPositive: friendly staff\\n\\nNegative: cold food\\nPositive: hot food'\n",
    "examples_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26d4bffd-3a91-4f9b-8cef-3bc3b1667b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"she said she'd be back and disappeared for a few minutes.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = sentences_negative[3]\n",
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "172f768e-1b6e-4d45-905f-c191dc88d676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Negative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: awful service\\nPositive: great service\\n\\nNegative: worst experience\\nPositive: best experience\\n\\nNegative: not good at all\\nPositive: very good\\n\\nNegative: disappointing meal\\nPositive: amazing meal\\n\\nNegative: horrible place\\nPositive: wonderful place\\n\\nNegative: never coming back\\nPositive: definitely coming back\\n\\nNegative: waste of money\\nPositive: worth the money\\n\\nNegative: rude staff\\nPositive: friendly staff\\n\\nNegative: cold food\\nPositive: hot food\\n\\nNegative: she said she'd be back and disappeared for a few minutes.\\nPositive: \""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'{examples_10}\\n\\nNegative: {sample_sentence}\\nPositive: '\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8517a591-d1d3-4b78-a081-845af6fb75b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Negative: the food was terrible\\nPositive: the food was excellent\\n\\nNegative: awful service\\nPositive: great service\\n\\nNegative: worst experience\\nPositive: best experience\\n\\nNegative: not good at all\\nPositive: very good\\n\\nNegative: disappointing meal\\nPositive: amazing meal\\n\\nNegative: horrible place\\nPositive: wonderful place\\n\\nNegative: never coming back\\nPositive: definitely coming back\\n\\nNegative: waste of money\\nPositive: worth the money\\n\\nNegative: rude staff\\nPositive: friendly staff\\n\\nNegative: cold food\\nPositive: hot food\\n\\nNegative: she said she'd be back and disappeared for a few minutes.\\nPositive:  she was back in 30 seconds.\\n\\nNegative: the food was terrible\\nPositive: the food was delicious\\n\\nNegative: the service was terrible\\nPositive: the service was excellent\\n\\nNeg\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7c31661-b745-418e-8d34-f59bdf72bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_10 = []\n",
    "references_10 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cf6a56c-0156-4cda-abbb-887d393315b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    prompt = f'{examples_10}\\n\\nNegative: {sentences_negative[i]}\\nPositive: '\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    pred = output.split('Positive:')[-1].strip() if 'Positive:' in output else output.split('\\n')[-1].strip()\n",
    "    predictions_10.append(pred)\n",
    "    references_10.append(sentences_positive[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58e0627b-51b4-4900-83d9-89db2828ecf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [0.08163265306122448, 0.0, 0.0, 0.0],\n",
       " 'brevity_penalty': 0.3531662652616454,\n",
       " 'length_ratio': 0.49,\n",
       " 'translation_length': 49,\n",
       " 'reference_length': 100}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=predictions_10, references=[[ref] for ref in references_10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b45575a4-ec10-474d-811a-1d334cdad6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': [0.3190222382545471,\n",
       "  0.3569352328777313,\n",
       "  0.3579205274581909,\n",
       "  0.4621596038341522,\n",
       "  0.3346001207828522,\n",
       "  0.2986333966255188,\n",
       "  0.32461729645729065,\n",
       "  0.0,\n",
       "  0.361230731010437,\n",
       "  0.3829004168510437],\n",
       " 'recall': [0.343608021736145,\n",
       "  0.44789159297943115,\n",
       "  0.5275716185569763,\n",
       "  0.5749461054801941,\n",
       "  0.43461373448371887,\n",
       "  0.4130258858203888,\n",
       "  0.3504026532173157,\n",
       "  0.0,\n",
       "  0.3670108914375305,\n",
       "  0.49886780977249146],\n",
       " 'f1': [0.3308590054512024,\n",
       "  0.3972737193107605,\n",
       "  0.4264943599700928,\n",
       "  0.5124199986457825,\n",
       "  0.3781050145626068,\n",
       "  0.3466358780860901,\n",
       "  0.3370174765586853,\n",
       "  0.0,\n",
       "  0.3640978932380676,\n",
       "  0.4332582652568817],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=predictions_10, references=references_10, model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7a9cc-6732-4765-a422-509ab908fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Овој модел не е подобар од моделите во претходните лапараториски вежби"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
