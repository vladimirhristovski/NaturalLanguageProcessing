{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2130f3f3-67a4-4c47-bab9-013c86861e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "from seq2seq import train_transformer, decode_with_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7117f7-d03c-4680-9298-1567d7fe3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('yelp_parallel/test_en_parallel.txt', sep='\\t')\n",
    "data.columns = ['Style1', 'Style2']\n",
    "data = data[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0084789-61c5-4d3c-b682-a76f9c07f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_negative = data['Style1'].values.tolist()\n",
    "sentences_positive = data['Style2'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc19fadb-d8aa-4711-ba12-96ab21482c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 't5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82d68dd-df22-4fe4-81e4-fd056892bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_transform = 'Transform negative sentiment to positive sentiment: '\n",
    "inputs_transform = [f'{instruction_transform}{s}' for s in sentences_negative]\n",
    "outputs_transform = sentences_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6d3930-3ed4-43f6-b495-a8bbbc97ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_classify = 'Classify the sentiment as positive or negative: '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630396ba-a71a-4635-8967-1d4b65ad1f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_classify_neg = [f'{instruction_classify}{s}' for s in sentences_negative]\n",
    "outputs_classify_neg = ['negative'] * len(sentences_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a05075-a2a4-4150-bb9f-5d0638a4c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_classify_pos = [f'{instruction_classify}{s}' for s in sentences_positive]\n",
    "outputs_classify_pos = ['positive'] * len(sentences_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2aff653-ad5f-4c09-b9a6-eafc82fd3607",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = inputs_transform + inputs_classify_neg + inputs_classify_pos\n",
    "all_outputs = outputs_transform + outputs_classify_neg + outputs_classify_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb3f6546-5469-4603-b50c-8f03b244b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_enc = tokenizer(all_inputs, max_length=128, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54dde4d9-4cec-40c0-b0bb-d3f4aaba9f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vlade\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    outputs_enc = tokenizer(all_outputs, max_length=128, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac49f572-5450-4e75-8c2b-c052950ded5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Dataset.from_dict({'input_ids': inputs_enc['input_ids'],\n",
    "                              'attention_mask': inputs_enc['attention_mask'],\n",
    "                              'labels': outputs_enc['input_ids']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91901279-f877-45d7-a913-ca621f0d77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1394e0dd-f321-4da5-ba0f-65db9c392914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 1.5538\n",
      "Epoch 2/3, Loss: 1.1652\n",
      "Epoch 3/3, Loss: 0.9277\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
    "optimizer = AdamW(model.parameters(), lr=0.001)\n",
    "train_transformer(model, train_loader, optimizer, 3, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a6db42c-da34-47b3-9a67-8335f55798c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ever since joes has changed hands it's gotten better and better.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sentence = decode_with_transformer(inputs_transform[0], tokenizer, model, device='cuda')\n",
    "predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "912607fe-31ed-42bc-8796-fc0367ff06ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ever since joes has changed hands it's gotten better and better.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_sentence = sentences_positive[0]\n",
    "reference_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76aa6262-c8e5-4c49-b06a-50aef02f6c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.9036020036098448,\n",
       " 'precisions': [0.9166666666666666,\n",
       "  0.9090909090909091,\n",
       "  0.9,\n",
       "  0.8888888888888888],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0,\n",
       " 'translation_length': 12,\n",
       " 'reference_length': 12}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu = load('bleu')\n",
    "bleu.compute(predictions=[predicted_sentence], references=[[reference_sentence]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c15aa33e-b1ac-4e0d-933c-4f08953203e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.9945324659347534],\n",
       " 'recall': [0.9945324659347534],\n",
       " 'f1': [0.9945324659347534],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore = load('bertscore')\n",
    "bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence], model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5a6bf04-d26d-45c1-a552-eb220c8acbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97f155b1-4c6c-48e2-84a7-fdc0b8694089",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    pred = decode_with_transformer(inputs_classify_neg[i], tokenizer, model, device='cuda')\n",
    "    if 'negative' in pred.lower():\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66557c17-ce81-44a3-b544-5686f909e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    pred = decode_with_transformer(inputs_classify_pos[i], tokenizer, model, device='cuda')\n",
    "    if 'positive' in pred.lower():\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05e8b029-cd9c-48ba-8e31-6b01fde0411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "170e195d-86b5-4e18-9590-b1d01df1d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.8632\n",
      "Epoch 2/5, Loss: 1.4576\n",
      "Epoch 3/5, Loss: 1.3606\n",
      "Epoch 4/5, Loss: 1.2697\n",
      "Epoch 5/5, Loss: 1.1914\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001)\n",
    "train_transformer(model, train_loader, optimizer, 5, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "621ab706-bc45-4613-9719-d3066c005ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"since joes has changed hands it's just getting better and better.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sentence = decode_with_transformer(inputs_transform[0], tokenizer, model, device='cuda')\n",
    "predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dffc69b2-2c81-46cb-b4ed-80aaa5e4811c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.6340466277046861,\n",
       " 'precisions': [0.8333333333333334,\n",
       "  0.7272727272727273,\n",
       "  0.6,\n",
       "  0.4444444444444444],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0,\n",
       " 'translation_length': 12,\n",
       " 'reference_length': 12}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=[predicted_sentence], references=[[reference_sentence]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bac43f0f-1439-4edd-80ba-e6933f74607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.9453003406524658],\n",
       " 'recall': [0.9484442472457886],\n",
       " 'f1': [0.9468696713447571],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence], model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "927494cb-a5d8-42ae-a426-2fcd0fa50b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a54fbeb-a76d-4a3e-997f-0251bb8a0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    pred = decode_with_transformer(inputs_classify_neg[i], tokenizer, model, device='cuda')\n",
    "    if 'negative' in pred.lower():\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e7607b5-07db-40de-8d32-ffc862166cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    pred = decode_with_transformer(inputs_classify_pos[i], tokenizer, model, device='cuda')\n",
    "    if 'positive' in pred.lower():\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9534784-d308-4f43-8b5c-d5dd8e443980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09476645-9669-4361-88d0-1cffec1a2fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Loss: 1.5613\n",
      "Epoch 2/7, Loss: 1.2165\n",
      "Epoch 3/7, Loss: 1.0154\n",
      "Epoch 4/7, Loss: 0.8598\n",
      "Epoch 5/7, Loss: 0.7261\n",
      "Epoch 6/7, Loss: 0.6035\n",
      "Epoch 7/7, Loss: 0.4989\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
    "optimizer = AdamW(model.parameters(), lr=0.0005)\n",
    "train_transformer(model, train_loader, optimizer, 7, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ba31442-526b-495e-83c7-810e0f8f7c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ever since joes has changed hands it's gotten better and better.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sentence = decode_with_transformer(inputs_transform[0], tokenizer, model, device='cuda')\n",
    "predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57cd0f2d-e42a-43a7-95a7-61d47d82eb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 1.0,\n",
       " 'precisions': [1.0, 1.0, 1.0, 1.0],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0,\n",
       " 'translation_length': 12,\n",
       " 'reference_length': 12}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=[predicted_sentence], references=[[reference_sentence]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ca2fa30-6e4e-45b7-ba7d-da4353b95335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [1.0],\n",
       " 'recall': [1.0],\n",
       " 'f1': [1.0],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence], model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec1a3b93-cf3c-468b-8503-0ef711b1bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "727bf42e-4f0c-4ed7-9d4b-894a1ba55ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    pred = decode_with_transformer(inputs_classify_neg[i], tokenizer, model, device='cuda')\n",
    "    if 'negative' in pred.lower():\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e712bbe-253d-4003-93a6-a1513a204e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    pred = decode_with_transformer(inputs_classify_pos[i], tokenizer, model, device='cuda')\n",
    "    if 'positive' in pred.lower():\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95751359-dc02-4e8a-9ff6-aad8ba911f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "034f12e1-4b7a-40be-9b33-b8b18d298c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подзадача 1: \n",
    "# BLEU: 0.90, 0.63, 1.0\n",
    "# BERTScore: 0.99, 0.94, 1.0\n",
    "# Како заклучок од овие тестирања можеме да заклучиме дека зголемувањето на епохите директно влијае врз резултатот\n",
    "# Осносно бројот на епохи има поголем удел во резултатите од ратата на учење\n",
    "# Тоа се докажува со овој експеримент каде со 7 епохи и рата на учење 0.0005 добивме перфектен резултат\n",
    "#\n",
    "# Подзадача 2:\n",
    "# Добиени резултати: 0.9, 0.8, 1.0\n",
    "# Заклучоците се исти како за Задача 1\n",
    "#\n",
    "# Во seq2seq скриптата зголемен е опсегот од 10 на 128 зборови"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
