{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d202566-a1a5-45d7-bf51-66ee92f3a774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vlade\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d295c2-44cb-4c7f-9709-f9bacc5f4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('yelp/train_en.txt', sep='\\t')[['Sentence', 'Style']]\n",
    "val   = pd.read_csv('yelp/val_en.txt', sep='\\t')[['Sentence', 'Style']]\n",
    "test  = pd.read_csv('yelp/test_en.txt', sep='\\t')[['Sentence', 'Style']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec11102-ad42-4d96-a192-b7589115741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small = train.sample(5000, random_state=42)\n",
    "val_small   = val.sample(2000, random_state=42)\n",
    "test_small  = test.sample(2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e15e15-216c-4ef9-813b-fa24924dc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'positive': 1, 'negative': 0}\n",
    "for df in [train_small, val_small, test_small]:\n",
    "    df['Label'] = df['Style'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ffd0337-d3a0-404b-8564-fc794b8d3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len=128):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = str(self.sentences[idx])\n",
    "        encoding = self.tokenizer(sentence, \n",
    "                                  padding='max_length', \n",
    "                                  truncation=True,\n",
    "                                  max_length=self.max_len,\n",
    "                                  return_tensors='pt')\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c4da96-e06c-41f1-a053-84b1a5a7a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_transformer(model_name, train_df, val_df, test_df, epochs=1, lr=5e-5):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "    train_dataset = YelpDataset(train_df['Sentence'].tolist(), train_df['Label'].tolist(), tokenizer)\n",
    "    val_dataset   = YelpDataset(val_df['Sentence'].tolist(), val_df['Label'].tolist(), tokenizer)\n",
    "    test_dataset  = YelpDataset(test_df['Sentence'].tolist(), test_df['Label'].tolist(), tokenizer)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'{model_name}_results',\n",
    "        eval_strategy=\"epoch\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        save_strategy=\"no\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        preds = p.predictions.argmax(-1)\n",
    "        labels = p.label_ids\n",
    "        return {\n",
    "            'accuracy': accuracy_score(labels, preds),\n",
    "            'precision': precision_score(labels, preds),\n",
    "            'recall': recall_score(labels, preds),\n",
    "            'f1': f1_score(labels, preds)\n",
    "        }\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    results = trainer.predict(test_dataset)\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(test_df['Label'], results.predictions.argmax(-1)),\n",
    "        'precision': precision_score(test_df['Label'], results.predictions.argmax(-1)),\n",
    "        'recall': recall_score(test_df['Label'], results.predictions.argmax(-1)),\n",
    "        'f1': f1_score(test_df['Label'], results.predictions.argmax(-1))\n",
    "    }\n",
    "    print(f\"\\nResults for {model_name} (lr={lr}, epochs={epochs}): {metrics}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3079d291-53ca-48ff-ab8a-d6b16f7721a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"roberta-base\", \"distilbert-base-uncased\"]\n",
    "lr_list = [5e-5, 3e-5, 1e-5]\n",
    "epoch_list = [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e96eb9-c823-4e71-80a4-b3938e45be1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 07:49, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.430500</td>\n",
       "      <td>0.403898</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.896384</td>\n",
       "      <td>0.902029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.290900</td>\n",
       "      <td>0.456899</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.914442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for roberta-base (lr=5e-05, epochs=2): {'accuracy': 0.8925, 'precision': 0.9109176155391828, 'recall': 0.9431345353675451, 'f1': 0.9267461669505963}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 11:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.434300</td>\n",
       "      <td>0.494787</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.871349</td>\n",
       "      <td>0.900791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.422773</td>\n",
       "      <td>0.875500</td>\n",
       "      <td>0.912561</td>\n",
       "      <td>0.914465</td>\n",
       "      <td>0.913512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.507701</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.911202</td>\n",
       "      <td>0.927677</td>\n",
       "      <td>0.919366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for roberta-base (lr=5e-05, epochs=3): {'accuracy': 0.8935, 'precision': 0.9132481506388702, 'recall': 0.941747572815534, 'f1': 0.9272789347900308}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 07:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.410700</td>\n",
       "      <td>0.349347</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.894426</td>\n",
       "      <td>0.948540</td>\n",
       "      <td>0.920688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.431316</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.901455</td>\n",
       "      <td>0.947844</td>\n",
       "      <td>0.924068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for roberta-base (lr=3e-05, epochs=2): {'accuracy': 0.9005, 'precision': 0.9118621603711067, 'recall': 0.9542302357836339, 'f1': 0.9325652321247034}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 11:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.434467</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>0.888454</td>\n",
       "      <td>0.947149</td>\n",
       "      <td>0.916863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.461599</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.905571</td>\n",
       "      <td>0.926982</td>\n",
       "      <td>0.916151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.544567</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.921419</td>\n",
       "      <td>0.916004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for roberta-base (lr=3e-05, epochs=3): {'accuracy': 0.9, 'precision': 0.9253424657534246, 'recall': 0.9368932038834952, 'f1': 0.9310820124052378}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 07:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.317304</td>\n",
       "      <td>0.884500</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.957580</td>\n",
       "      <td>0.922613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.288200</td>\n",
       "      <td>0.456354</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.903034</td>\n",
       "      <td>0.952017</td>\n",
       "      <td>0.926879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for roberta-base (lr=1e-05, epochs=2): {'accuracy': 0.897, 'precision': 0.9012987012987013, 'recall': 0.9625520110957004, 'f1': 0.9309188464118041}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 11:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.341688</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.947844</td>\n",
       "      <td>0.926581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>0.442015</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.912955</td>\n",
       "      <td>0.940890</td>\n",
       "      <td>0.926712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.893500</td>\n",
       "      <td>0.914692</td>\n",
       "      <td>0.939499</td>\n",
       "      <td>0.926930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for roberta-base (lr=1e-05, epochs=3): {'accuracy': 0.9055, 'precision': 0.9190635451505017, 'recall': 0.9528432732316228, 'f1': 0.9356486210418795}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59feaf369efc437bb377d5024166dc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701096931a6146c19dbdd5119c5668d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c73e4cad9442d086af445de2c3e78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6b3daa73234c5a9e3d3351d078c5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79579c28ee734ae5bcd06724687659fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 04:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>0.393057</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>0.906295</td>\n",
       "      <td>0.881085</td>\n",
       "      <td>0.893512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>0.490074</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.924896</td>\n",
       "      <td>0.905378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for distilbert-base-uncased (lr=5e-05, epochs=2): {'accuracy': 0.8745, 'precision': 0.9004707464694015, 'recall': 0.9285714285714286, 'f1': 0.9143052236258109}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 06:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>0.352095</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.903546</td>\n",
       "      <td>0.885953</td>\n",
       "      <td>0.894663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.491600</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.902371</td>\n",
       "      <td>0.899861</td>\n",
       "      <td>0.901114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.589808</td>\n",
       "      <td>0.858500</td>\n",
       "      <td>0.893125</td>\n",
       "      <td>0.912378</td>\n",
       "      <td>0.902649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for distilbert-base-uncased (lr=5e-05, epochs=3): {'accuracy': 0.8695, 'precision': 0.8981793661496965, 'recall': 0.9237170596393898, 'f1': 0.9107692307692308}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 04:01, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.389900</td>\n",
       "      <td>0.346671</td>\n",
       "      <td>0.859500</td>\n",
       "      <td>0.887995</td>\n",
       "      <td>0.920723</td>\n",
       "      <td>0.904063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.464705</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.889037</td>\n",
       "      <td>0.924896</td>\n",
       "      <td>0.906612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for distilbert-base-uncased (lr=3e-05, epochs=2): {'accuracy': 0.875, 'precision': 0.8994638069705094, 'recall': 0.9306518723994452, 'f1': 0.9147920927062031}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 06:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.396400</td>\n",
       "      <td>0.338364</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.895634</td>\n",
       "      <td>0.913074</td>\n",
       "      <td>0.904270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.255200</td>\n",
       "      <td>0.440594</td>\n",
       "      <td>0.865500</td>\n",
       "      <td>0.906750</td>\n",
       "      <td>0.906120</td>\n",
       "      <td>0.906435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.572945</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.899796</td>\n",
       "      <td>0.917942</td>\n",
       "      <td>0.908778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for distilbert-base-uncased (lr=3e-05, epochs=3): {'accuracy': 0.874, 'precision': 0.9047619047619048, 'recall': 0.9223300970873787, 'f1': 0.9134615384615384}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 04:01, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.371343</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.894053</td>\n",
       "      <td>0.909597</td>\n",
       "      <td>0.901758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.289400</td>\n",
       "      <td>0.436086</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.882818</td>\n",
       "      <td>0.932545</td>\n",
       "      <td>0.907000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for distilbert-base-uncased (lr=1e-05, epochs=2): {'accuracy': 0.876, 'precision': 0.9006711409395973, 'recall': 0.9306518723994452, 'f1': 0.9154160982264665}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 06:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.900976</td>\n",
       "      <td>0.898470</td>\n",
       "      <td>0.899721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.399385</td>\n",
       "      <td>0.864500</td>\n",
       "      <td>0.898294</td>\n",
       "      <td>0.915160</td>\n",
       "      <td>0.906648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.474237</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.886968</td>\n",
       "      <td>0.927677</td>\n",
       "      <td>0.906866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for distilbert-base-uncased (lr=1e-05, epochs=3): {'accuracy': 0.8765, 'precision': 0.9007377598926894, 'recall': 0.9313453536754508, 'f1': 0.9157858847596317}\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "for model_name, lr, epochs in itertools.product(model_names, lr_list, epoch_list):\n",
    "    res = train_evaluate_transformer(model_name, train_small, val_small, test_small, epochs=epochs, lr=lr)\n",
    "    all_results.append({\n",
    "        'model': model_name,\n",
    "        'lr': lr,\n",
    "        'epochs': epochs,\n",
    "        **res\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0609fb95-ac4d-46de-856e-c2c85d431d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      model       lr  epochs  accuracy  precision    recall  \\\n",
      "0              roberta-base  0.00005       2    0.8925   0.910918  0.943135   \n",
      "1              roberta-base  0.00005       3    0.8935   0.913248  0.941748   \n",
      "2              roberta-base  0.00003       2    0.9005   0.911862  0.954230   \n",
      "3              roberta-base  0.00003       3    0.9000   0.925342  0.936893   \n",
      "4              roberta-base  0.00001       2    0.8970   0.901299  0.962552   \n",
      "5              roberta-base  0.00001       3    0.9055   0.919064  0.952843   \n",
      "6   distilbert-base-uncased  0.00005       2    0.8745   0.900471  0.928571   \n",
      "7   distilbert-base-uncased  0.00005       3    0.8695   0.898179  0.923717   \n",
      "8   distilbert-base-uncased  0.00003       2    0.8750   0.899464  0.930652   \n",
      "9   distilbert-base-uncased  0.00003       3    0.8740   0.904762  0.922330   \n",
      "10  distilbert-base-uncased  0.00001       2    0.8760   0.900671  0.930652   \n",
      "11  distilbert-base-uncased  0.00001       3    0.8765   0.900738  0.931345   \n",
      "\n",
      "          f1  \n",
      "0   0.926746  \n",
      "1   0.927279  \n",
      "2   0.932565  \n",
      "3   0.931082  \n",
      "4   0.930919  \n",
      "5   0.935649  \n",
      "6   0.914305  \n",
      "7   0.910769  \n",
      "8   0.914792  \n",
      "9   0.913462  \n",
      "10  0.915416  \n",
      "11  0.915786  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(all_results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3326efc7-37db-4071-ad43-14b577ac25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Со менување на хиперпараметрите, перформансите на моделот минимално се менуваа\n",
    "# Резултатите споредени со моделите од првата лабараториска вежба се скоро исти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce4339-c45b-4b4f-a3d8-a683504f5745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
