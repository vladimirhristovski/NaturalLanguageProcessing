{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNTC5Nm45a7w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from evaluate import load\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=os.getenv('HF_TOKEN'))"
      ],
      "metadata": {
        "id": "XopDZCBA6EYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('yelp_parallel/test_en_parallel.txt', sep='\\t')\n",
        "data.columns = ['Style1', 'Style2']\n",
        "data = data[:5000]"
      ],
      "metadata": {
        "id": "BICtSmN36HF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_negative = data['Style1'].values.tolist()\n",
        "sentences_positive = data['Style2'].values.tolist()"
      ],
      "metadata": {
        "id": "s9QCb9He6LQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = sentences_positive"
      ],
      "metadata": {
        "id": "PES6uNM56MlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "document_embeddings = embeddings_model.encode(documents, batch_size=64, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "jNiSjQPf6NBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'meta-llama/Llama-2-7b-hf'\n",
        "bitsandbytes_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                         bnb_4bit_compute_dtype=torch.float16,\n",
        "                                         bnb_4bit_quant_type='nf4')"
      ],
      "metadata": {
        "id": "c_ULGzPL6NUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             quantization_config=bitsandbytes_config,\n",
        "                                             device_map='cuda:0')"
      ],
      "metadata": {
        "id": "fvEWH6GD6NnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = load('bleu')\n",
        "bertscore = load('bertscore')"
      ],
      "metadata": {
        "id": "65nnGwP16N1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Експеримент 1: RAG со 5 документи\n",
        "sample_sentence = sentences_negative[0]\n",
        "sample_sentence"
      ],
      "metadata": {
        "id": "4WyM74dO6OFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_embedding = embeddings_model.encode(sample_sentence, batch_size=64, show_progress_bar=True)\n",
        "context_results = util.semantic_search(sample_embedding, document_embeddings, top_k=5)\n",
        "context_results"
      ],
      "metadata": {
        "id": "PcEsDYOv6OXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
        "doc_ids"
      ],
      "metadata": {
        "id": "NRRWCIma6Otk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [documents[d] for d in doc_ids]\n",
        "docs"
      ],
      "metadata": {
        "id": "a1WLE1XV6PZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = f'Context:\\nExample 1: {docs[0]}\\nExample 2: {docs[1]}\\nExample 3: {docs[2]}\\nExample 4: {docs[3]}\\nExample 5: {docs[4]}'\n",
        "context"
      ],
      "metadata": {
        "id": "IrhsLNYQ6PqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'{context}\\n\\nTransform the following negative sentence to positive: {sample_sentence}\\nPositive: '\n",
        "prompt"
      ],
      "metadata": {
        "id": "mlFdYh_r6P7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
        "tokens"
      ],
      "metadata": {
        "id": "PFMHxfM46QKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
        "output_ids"
      ],
      "metadata": {
        "id": "ojD3Zqin6QZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(output_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "PweWuovF6Qty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_5 = []\n",
        "references_5 = []"
      ],
      "metadata": {
        "id": "5tYRHJaw6Q7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    negative_sent = sentences_negative[i]\n",
        "    positive_sent = sentences_positive[i]\n",
        "\n",
        "    sent_embedding = embeddings_model.encode(negative_sent)\n",
        "    context_results = util.semantic_search(sent_embedding, document_embeddings, top_k=5)\n",
        "    doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
        "    docs = [documents[d] for d in doc_ids]\n",
        "    context = f'Context:\\nExample 1: {docs[0]}\\nExample 2: {docs[1]}\\nExample 3: {docs[2]}\\nExample 4: {docs[3]}\\nExample 5: {docs[4]}'\n",
        "\n",
        "    prompt = f'{context}\\n\\nTransform the following negative sentence to positive: {negative_sent}\\nPositive: '\n",
        "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
        "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
        "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    if 'Positive:' in output:\n",
        "        pred = output.split('Positive:')[-1].strip()\n",
        "    else:\n",
        "        pred = output.split('\\n')[-1].strip()\n",
        "\n",
        "    predictions_5.append(pred)\n",
        "    references_5.append(positive_sent)"
      ],
      "metadata": {
        "id": "27OV7NHU6RKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu.compute(predictions=predictions_5, references=[[ref] for ref in references_5])"
      ],
      "metadata": {
        "id": "pLpJYWQv6RYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertscore.compute(predictions=predictions_5, references=references_5, model_type='microsoft/deberta-xlarge-mnli')"
      ],
      "metadata": {
        "id": "vkJ9N-7P6Rzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Експеримент 2: RAG со 3 документи\n",
        "sample_sentence = sentences_negative[5]\n",
        "sample_sentence"
      ],
      "metadata": {
        "id": "qDusAk1C6SPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_embedding = embeddings_model.encode(sample_sentence, batch_size=64, show_progress_bar=True)\n",
        "context_results = util.semantic_search(sent_embedding, document_embeddings, top_k=3)\n",
        "doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
        "docs = [documents[d] for d in doc_ids]"
      ],
      "metadata": {
        "id": "qdGKZjy76SgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = f'Context:\\nExample 1: {docs[0]}\\nExample 2: {docs[1]}\\nExample 3: {docs[2]}'\n",
        "context"
      ],
      "metadata": {
        "id": "6ZnMROw2mhpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_3 = []\n",
        "references_3 = []"
      ],
      "metadata": {
        "id": "wIqL_kQ76Szw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    negative_sent = sentences_negative[i]\n",
        "    positive_sent = sentences_positive[i]\n",
        "\n",
        "    sent_embedding = embeddings_model.encode(negative_sent)\n",
        "    context_results = util.semantic_search(sent_embedding, document_embeddings, top_k=3)\n",
        "    doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
        "    docs = [documents[d] for d in doc_ids]\n",
        "    context = f'Context:\\nExample 1: {docs[0]}\\nExample 2: {docs[1]}\\nExample 3: {docs[2]}'\n",
        "\n",
        "    prompt = f'{context}\\n\\nTransform the following negative sentence to positive: {negative_sent}\\nPositive: '\n",
        "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
        "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
        "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    if 'Positive:' in output:\n",
        "        pred = output.split('Positive:')[-1].strip()\n",
        "    else:\n",
        "        pred = output.split('\\n')[-1].strip()\n",
        "\n",
        "    predictions_3.append(pred)\n",
        "    references_3.append(positive_sent)"
      ],
      "metadata": {
        "id": "pZf7DFFh7V_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu.compute(predictions=predictions_3, references=[[ref] for ref in references_3])"
      ],
      "metadata": {
        "id": "dFNtxPoZmpJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertscore.compute(predictions=predictions_3, references=references_3, model_type='microsoft/deberta-xlarge-mnli')"
      ],
      "metadata": {
        "id": "wanSyAvJ7WSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Експеримент 3: RAG со 1 документ\n",
        "sample_sentence = sentences_negative[10]\n",
        "sample_sentence"
      ],
      "metadata": {
        "id": "j0KwktXB7WiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_embedding = embeddings_model.encode(sample_sentence, batch_size=64, show_progress_bar=True)\n",
        "context_results = util.semantic_search(sent_embedding, document_embeddings, top_k=1)\n",
        "doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
        "docs = [documents[d] for d in doc_ids]"
      ],
      "metadata": {
        "id": "pbDwcuO27W0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = f'Context:\\nExample 1: {docs[0]}'\n",
        "context"
      ],
      "metadata": {
        "id": "1Uh1ktz4mwQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1 = []\n",
        "references_1 = []"
      ],
      "metadata": {
        "id": "uwep0mH47XS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    negative_sent = sentences_negative[i]\n",
        "    positive_sent = sentences_positive[i]\n",
        "\n",
        "    sent_embedding = embeddings_model.encode(negative_sent)\n",
        "    context_results = util.semantic_search(sent_embedding, document_embeddings, top_k=1)\n",
        "    doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
        "    docs = [documents[d] for d in doc_ids]\n",
        "    context = f'Context:\\nExample 1: {docs[0]}'\n",
        "\n",
        "    prompt = f'{context}\\n\\nTransform the following negative sentence to positive: {negative_sent}\\nPositive: '\n",
        "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
        "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
        "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    if 'Positive:' in output:\n",
        "        pred = output.split('Positive:')[-1].strip()\n",
        "    else:\n",
        "        pred = output.split('\\n')[-1].strip()\n",
        "\n",
        "    predictions_1.append(pred)\n",
        "    references_1.append(positive_sent)"
      ],
      "metadata": {
        "id": "Or7DUs307XhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu.compute(predictions=predictions_1, references=[[ref] for ref in references_1])"
      ],
      "metadata": {
        "id": "x14mIk0T7Xui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertscore.compute(predictions=predictions_1, references=references_1, model_type='microsoft/deberta-xlarge-mnli')"
      ],
      "metadata": {
        "id": "hLuUU5f37X-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Експеримент 4: Друг embedding модел (all-distilroberta-v1)\n",
        "embeddings_model_distil = SentenceTransformer('all-distilroberta-v1')\n",
        "document_embeddings_distil = embeddings_model_distil.encode(documents, batch_size=64, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "j0gnNgp37YNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = sentences_negative[8]\n",
        "sample_sentence"
      ],
      "metadata": {
        "id": "VCCmd0BX7YcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_embedding = embeddings_model_distil.encode(sample_sentence, batch_size=64, show_progress_bar=True)\n",
        "context_results = util.semantic_search(sent_embedding, document_embeddings_distil, top_k=5)\n",
        "doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
        "docs = [documents[d] for d in doc_ids]\n",
        "docs"
      ],
      "metadata": {
        "id": "-PF2f-ls7vdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_distil = []\n",
        "references_distil = []"
      ],
      "metadata": {
        "id": "1K9CLnp17vuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    negative_sent = sentences_negative[i]\n",
        "    positive_sent = sentences_positive[i]\n",
        "\n",
        "    sent_embedding = embeddings_model_distil.encode(negative_sent)\n",
        "    context_results = util.semantic_search(sent_embedding, document_embeddings_distil, top_k=5)\n",
        "    doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
        "    docs = [documents[d] for d in doc_ids]\n",
        "    context = f'Context:\\nExample 1: {docs[0]}\\nExample 2: {docs[1]}\\nExample 3: {docs[2]}\\nExample 4: {docs[3]}\\nExample 5: {docs[4]}'\n",
        "\n",
        "    prompt = f'{context}\\n\\nTransform the following negative sentence to positive: {negative_sent}\\nPositive: '\n",
        "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
        "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
        "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    if 'Positive:' in output:\n",
        "        pred = output.split('Positive:')[-1].strip()\n",
        "    else:\n",
        "        pred = output.split('\\n')[-1].strip()\n",
        "\n",
        "    predictions_distil.append(pred)\n",
        "    references_distil.append(positive_sent)"
      ],
      "metadata": {
        "id": "2lqi99f97wC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu.compute(predictions=predictions_distil, references=[[ref] for ref in references_distil])"
      ],
      "metadata": {
        "id": "3f45iVR67wcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertscore.compute(predictions=predictions_distil, references=references_distil, model_type='microsoft/deberta-xlarge-mnli')"
      ],
      "metadata": {
        "id": "sDciBz8H7wqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Експеримент 5: Zero-shot (без контекст)\n",
        "sample_sentence = sentences_negative[12]\n",
        "sample_sentence"
      ],
      "metadata": {
        "id": "_XiQkaBa7w8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'Transform the following negative sentence to positive: {sample_sentence}\\nPositive: '\n",
        "prompt"
      ],
      "metadata": {
        "id": "R6X9APm27xN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
        "output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
        "tokenizer.decode(output_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "lm4GCg0-7xbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_zero = []\n",
        "references_zero = []"
      ],
      "metadata": {
        "id": "E1d2Ou4w7yCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    negative_sent = sentences_negative[i]\n",
        "    positive_sent = sentences_positive[i]\n",
        "\n",
        "    prompt = f'Transform the following negative sentence to positive: {negative_sent}\\nPositive: '\n",
        "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
        "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
        "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    if 'Positive:' in output:\n",
        "        pred = output.split('Positive:')[-1].strip()\n",
        "    else:\n",
        "        pred = output.split('\\n')[-1].strip()\n",
        "\n",
        "    predictions_zero.append(pred)\n",
        "    references_zero.append(positive_sent)"
      ],
      "metadata": {
        "id": "49plRrXR7yRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu.compute(predictions=predictions_zero, references=[[ref] for ref in references_zero])"
      ],
      "metadata": {
        "id": "jXuW3hJi7ygI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertscore.compute(predictions=predictions_zero, references=references_zero, model_type='microsoft/deberta-xlarge-mnli')"
      ],
      "metadata": {
        "id": "ftWQlpqJ7yuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG со 5 документи даде одговор на 3 од 10 обиди, со просечен bertscore од 0.65\n",
        "# RAG со 3 документи даде одговор на 6 од 10 обиди, со просечен bertscore од 0.65\n",
        "# RAG со 1 документ даде одговор на 4 од 10 обиди, со просечен bertscore од 0.75\n",
        "# RAG со DistilRoberta даде одговор на 4 од 10 обиди, со просечен bertscore од 0.65\n",
        "# Zero-shot без контекст, даде одговор на 0 од 10 обиди\n",
        "#\n",
        "# Според добиените резултати можеме да заклучиме дека RAG со 1 догумент даде најдобри резултати од сите останати тестови.\n",
        "# RAG со DistilRoberta даде идентичен резултат како и RAG со 5 и 3 документи, но не беа тие резултати најдобри\n",
        "# Со помош на zero-shot prompting се добија ужасни резултати, односно не добивме одговор за ни еден пример"
      ],
      "metadata": {
        "id": "7yHrepOX8OCm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}