{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DNTC5Nm45a7w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vlade\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from evaluate import load\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XopDZCBA6EYe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be11563f8f2d404d8e422d10ae20263e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login(token=os.getenv('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BICtSmN36HF_"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('yelp_parallel/test_en_parallel.txt', sep='\\t')\n",
    "data.columns = ['Style1', 'Style2']\n",
    "data = data[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s9QCb9He6LQi"
   },
   "outputs": [],
   "source": [
    "sentences_negative = data['Style1'].values.tolist()\n",
    "sentences_positive = data['Style2'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PES6uNM56MlA"
   },
   "outputs": [],
   "source": [
    "documents = sentences_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jNiSjQPf6NBN"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e0cf37cbec40c988501af781a43370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "document_embeddings = embeddings_model.encode(documents, batch_size=64, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c_ULGzPL6NUi"
   },
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "bitsandbytes_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.float16,\n",
    "                                         bnb_4bit_quant_type='nf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fvEWH6GD6NnW"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54a0ad56498478e9c02b4cd01912078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             quantization_config=bitsandbytes_config,\n",
    "                                             device_map='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "65nnGwP16N1j"
   },
   "outputs": [],
   "source": [
    "bleu = load('bleu')\n",
    "bertscore = load('bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4WyM74dO6OFn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ever since joes has changed hands it's just gotten worse and worse.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Експеримент 1: RAG со 5 документи\n",
    "sample_sentence = sentences_negative[0]\n",
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PcEsDYOv6OXa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a7777f29b64924a1846c991b377663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 0, 'score': 0.9348020553588867},\n",
       "  {'corpus_id': 418, 'score': 0.27251461148262024},\n",
       "  {'corpus_id': 130, 'score': 0.26488202810287476},\n",
       "  {'corpus_id': 89, 'score': 0.2495049089193344},\n",
       "  {'corpus_id': 361, 'score': 0.24265258014202118}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embedding = embeddings_model.encode(sample_sentence, batch_size=64, show_progress_bar=True)\n",
    "context_results = util.semantic_search(sample_embedding, document_embeddings, top_k=5)\n",
    "context_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NRRWCIma6Otk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 418, 130, 89, 361]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "a1WLE1XV6PZm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Ever since joes has changed hands it's gotten better and better.\",\n",
       " 'much more these days.',\n",
       " 'i expected so much less from this ny staple.',\n",
       " 'it seems it was warmed up a tad too bit',\n",
       " 'great what has happened to this sandwich shop.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [documents[d] for d in doc_ids]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IrhsLNYQ6PqM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Context:\\nExample 1: Ever since joes has changed hands it's gotten better and better.\\nExample 2: much more these days.\\nExample 3: i expected so much less from this ny staple.\\nExample 4: it seems it was warmed up a tad too bit\\nExample 5: great what has happened to this sandwich shop.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = f'Context:\\nExample 1: {docs[0]}\\nExample 2: {docs[1]}\\nExample 3: {docs[2]}\\nExample 4: {docs[3]}\\nExample 5: {docs[4]}'\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mlFdYh_r6P7C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Context:\\nExample 1: Ever since joes has changed hands it's gotten better and better.\\nExample 2: much more these days.\\nExample 3: i expected so much less from this ny staple.\\nExample 4: it seems it was warmed up a tad too bit\\nExample 5: great what has happened to this sandwich shop.\\n\\nTransform the following negative sentence to positive: ever since joes has changed hands it's just gotten worse and worse.\\nPositive: \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'{context}\\n\\nTransform the following negative sentence to positive: {sample_sentence}\\nPositive: '\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PFMHxfM46QKQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 15228, 29901,    13, 14023, 29871, 29896, 29901, 18274,  1951,\n",
       "          2958,   267,   756,  3939,  6567,   372, 29915, 29879,  2355,   841,\n",
       "          2253,   322,  2253, 29889,    13, 14023, 29871, 29906, 29901,  1568,\n",
       "           901,  1438,  3841, 29889,    13, 14023, 29871, 29941, 29901,   474,\n",
       "          3806,   577,  1568,  3109,   515,   445,  7098,   380,   481,   280,\n",
       "         29889,    13, 14023, 29871, 29946, 29901,   372,  2444,   372,   471,\n",
       "          1370,  2168,   701,   263,   260,   328,  2086,  2586,    13, 14023,\n",
       "         29871, 29945, 29901,  2107,   825,   756,  9559,   304,   445, 11982,\n",
       "         16416, 18296, 29889,    13,    13, 13372,   278,  1494,  8178, 10541,\n",
       "           304,  6374, 29901,  3926,  1951,  2958,   267,   756,  3939,  6567,\n",
       "           372, 29915, 29879,   925,  2355,   841, 15029,   322, 15029, 29889,\n",
       "            13,  9135,  3321, 29901, 29871]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:0')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ojD3Zqin6QZs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 15228, 29901,    13, 14023, 29871, 29896, 29901, 18274,  1951,\n",
       "          2958,   267,   756,  3939,  6567,   372, 29915, 29879,  2355,   841,\n",
       "          2253,   322,  2253, 29889,    13, 14023, 29871, 29906, 29901,  1568,\n",
       "           901,  1438,  3841, 29889,    13, 14023, 29871, 29941, 29901,   474,\n",
       "          3806,   577,  1568,  3109,   515,   445,  7098,   380,   481,   280,\n",
       "         29889,    13, 14023, 29871, 29946, 29901,   372,  2444,   372,   471,\n",
       "          1370,  2168,   701,   263,   260,   328,  2086,  2586,    13, 14023,\n",
       "         29871, 29945, 29901,  2107,   825,   756,  9559,   304,   445, 11982,\n",
       "         16416, 18296, 29889,    13,    13, 13372,   278,  1494,  8178, 10541,\n",
       "           304,  6374, 29901,  3926,  1951,  2958,   267,   756,  3939,  6567,\n",
       "           372, 29915, 29879,   925,  2355,   841, 15029,   322, 15029, 29889,\n",
       "            13,  9135,  3321, 29901, 29871,    13, 14023, 29871, 29953, 29901,\n",
       "          2958,   267,   756,  2355,   841, 15029,   322, 15029,  3926,  1951,\n",
       "           372,   756,  3939,  6567, 29889,    13, 14023, 29871, 29955, 29901,\n",
       "          2958,   267,   756,  2355,   841, 15029,   322, 15029,  3926,  1951,\n",
       "           372,   756,  3939,  6567, 29889,    13, 14023, 29871, 29947, 29901,\n",
       "          2958,   267,   756,  2355,   841]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PweWuovF6Qty"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Context:\\nExample 1: Ever since joes has changed hands it's gotten better and better.\\nExample 2: much more these days.\\nExample 3: i expected so much less from this ny staple.\\nExample 4: it seems it was warmed up a tad too bit\\nExample 5: great what has happened to this sandwich shop.\\n\\nTransform the following negative sentence to positive: ever since joes has changed hands it's just gotten worse and worse.\\nPositive: \\nExample 6: joes has gotten worse and worse ever since it has changed hands.\\nExample 7: joes has gotten worse and worse ever since it has changed hands.\\nExample 8: joes has gotten\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5tYRHJaw6Q7H"
   },
   "outputs": [],
   "source": [
    "predictions_5 = []\n",
    "references_5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "27OV7NHU6RKO"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    negative_sent = sentences_negative[i]\n",
    "    positive_sent = sentences_positive[i]\n",
    "\n",
    "    sent_embedding = embeddings_model.encode(negative_sent)\n",
    "    context_results = util.semantic_search(sent_embedding, document_embeddings, top_k=5)\n",
    "    doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
    "    docs = [documents[d] for d in doc_ids]\n",
    "    context = f'Context:\\nExample 1: {docs[0]}\\nExample 2: {docs[1]}\\nExample 3: {docs[2]}\\nExample 4: {docs[3]}\\nExample 5: {docs[4]}'\n",
    "\n",
    "    prompt = f'{context}\\n\\nTransform the following negative sentence to positive: {negative_sent}\\nPositive: '\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
    "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    if 'Positive:' in output:\n",
    "        pred = output.split('Positive:')[-1].strip()\n",
    "    else:\n",
    "        pred = output.split('\\n')[-1].strip()\n",
    "\n",
    "    predictions_5.append(pred)\n",
    "    references_5.append(positive_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pLpJYWQv6RYI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.10181444503483945,\n",
       " 'precisions': [0.20095693779904306,\n",
       "  0.10050251256281408,\n",
       "  0.07936507936507936,\n",
       "  0.0670391061452514],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 2.09,\n",
       " 'translation_length': 209,\n",
       " 'reference_length': 100}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=predictions_5, references=[[ref] for ref in references_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "vkJ9N-7P6Rzi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.3917850852012634,\n",
       "  0.7488517761230469,\n",
       "  0.4536862373352051,\n",
       "  0.5515203475952148,\n",
       "  0.7548274993896484,\n",
       "  0.45931288599967957,\n",
       "  0.5178031921386719,\n",
       "  0.5454379320144653,\n",
       "  0.5310631394386292,\n",
       "  0.44078490138053894],\n",
       " 'recall': [0.4670611023902893,\n",
       "  0.6535013318061829,\n",
       "  0.6453817486763,\n",
       "  0.6679890751838684,\n",
       "  0.6978453397750854,\n",
       "  0.6200667023658752,\n",
       "  0.8740153312683105,\n",
       "  0.7711831331253052,\n",
       "  0.46099597215652466,\n",
       "  0.5255774259567261],\n",
       " 'f1': [0.4261241853237152,\n",
       "  0.6979349851608276,\n",
       "  0.5328165888786316,\n",
       "  0.6041930913925171,\n",
       "  0.7252188324928284,\n",
       "  0.5277191400527954,\n",
       "  0.6503260731697083,\n",
       "  0.6389576196670532,\n",
       "  0.4935552179813385,\n",
       "  0.479461133480072],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=predictions_5, references=references_5, model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "qDusAk1C6SPb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'just left and took it off the bill.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Експеримент 2: RAG со 3 документи\n",
    "sample_sentence = sentences_negative[5]\n",
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qdGKZjy76SgY"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2118a9c5c042f7949a7f565af9345b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_embedding = embeddings_model.encode(sample_sentence, batch_size=64, show_progress_bar=True)\n",
    "context_results = util.semantic_search(sent_embedding, document_embeddings, top_k=3)\n",
    "doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
    "docs = [documents[d] for d in doc_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "6ZnMROw2mhpV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Context:\\nExample 1: just left and put it on the bill.\\nExample 2: He took care of the bill himself.\\nExample 3: i know i shouldn't have sent this back and walked out.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = f'Context:\\nExample 1: {docs[0]}\\nExample 2: {docs[1]}\\nExample 3: {docs[2]}'\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wIqL_kQ76Szw"
   },
   "outputs": [],
   "source": [
    "predictions_3 = []\n",
    "references_3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "pZf7DFFh7V_a"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    negative_sent = sentences_negative[i]\n",
    "    positive_sent = sentences_positive[i]\n",
    "\n",
    "    sent_embedding = embeddings_model.encode(negative_sent)\n",
    "    context_results = util.semantic_search(sent_embedding, document_embeddings, top_k=3)\n",
    "    doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
    "    docs = [documents[d] for d in doc_ids]\n",
    "    context = f'Context:\\nExample 1: {docs[0]}\\nExample 2: {docs[1]}\\nExample 3: {docs[2]}'\n",
    "\n",
    "    prompt = f'{context}\\n\\nTransform the following negative sentence to positive: {negative_sent}\\nPositive: '\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
    "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    if 'Positive:' in output:\n",
    "        pred = output.split('Positive:')[-1].strip()\n",
    "    else:\n",
    "        pred = output.split('\\n')[-1].strip()\n",
    "\n",
    "    predictions_3.append(pred)\n",
    "    references_3.append(positive_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "dFNtxPoZmpJz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.1061619130063686,\n",
       " 'precisions': [0.23140495867768596,\n",
       "  0.12612612612612611,\n",
       "  0.07920792079207921,\n",
       "  0.054945054945054944],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.21,\n",
       " 'translation_length': 121,\n",
       " 'reference_length': 100}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=predictions_3, references=[[ref] for ref in references_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wanSyAvJ7WSD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.5270600318908691,\n",
       "  0.7140408754348755,\n",
       "  0.5146754384040833,\n",
       "  0.4531857371330261,\n",
       "  0.5921239852905273,\n",
       "  0.4238852560520172,\n",
       "  0.7440032958984375,\n",
       "  0.7389216423034668,\n",
       "  0.48301970958709717,\n",
       "  0.42338812351226807],\n",
       " 'recall': [0.46220603585243225,\n",
       "  0.6450587511062622,\n",
       "  0.8828999996185303,\n",
       "  0.45786505937576294,\n",
       "  0.5934141874313354,\n",
       "  0.5669422149658203,\n",
       "  0.7878130674362183,\n",
       "  0.5587757229804993,\n",
       "  0.5196435451507568,\n",
       "  0.49340400099754333],\n",
       " 'f1': [0.4925071895122528,\n",
       "  0.6777992248535156,\n",
       "  0.6502789855003357,\n",
       "  0.4555133581161499,\n",
       "  0.5927683711051941,\n",
       "  0.4850863814353943,\n",
       "  0.7652816772460938,\n",
       "  0.6363447904586792,\n",
       "  0.5006627440452576,\n",
       "  0.455722451210022],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=predictions_3, references=references_3, model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "j0KwktXB7WiK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we sit down and we got some really slow and lazy service.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Експеримент 3: RAG со 1 документ\n",
    "sample_sentence = sentences_negative[10]\n",
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "pbDwcuO27W0P"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac7fb63d2624c6eb587c0116425f843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_embedding = embeddings_model.encode(sample_sentence, batch_size=64, show_progress_bar=True)\n",
    "context_results = util.semantic_search(sent_embedding, document_embeddings, top_k=1)\n",
    "doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
    "docs = [documents[d] for d in doc_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "1Uh1ktz4mwQj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context:\\nExample 1: services were fast and we tried to help everyone equally fast'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = f'Context:\\nExample 1: {docs[0]}'\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "uwep0mH47XS0"
   },
   "outputs": [],
   "source": [
    "predictions_1 = []\n",
    "references_1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Or7DUs307XhQ"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    negative_sent = sentences_negative[i]\n",
    "    positive_sent = sentences_positive[i]\n",
    "\n",
    "    sent_embedding = embeddings_model.encode(negative_sent)\n",
    "    context_results = util.semantic_search(sent_embedding, document_embeddings, top_k=1)\n",
    "    doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
    "    docs = [documents[d] for d in doc_ids]\n",
    "    context = f'Context:\\nExample 1: {docs[0]}'\n",
    "\n",
    "    prompt = f'{context}\\n\\nTransform the following negative sentence to positive: {negative_sent}\\nPositive: '\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
    "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    if 'Positive:' in output:\n",
    "        pred = output.split('Positive:')[-1].strip()\n",
    "    else:\n",
    "        pred = output.split('\\n')[-1].strip()\n",
    "\n",
    "    predictions_1.append(pred)\n",
    "    references_1.append(positive_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "x14mIk0T7Xui"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.12645444920082566,\n",
       " 'precisions': [0.21, 0.14659685863874344, 0.10382513661202186, 0.08],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 2.0,\n",
       " 'translation_length': 200,\n",
       " 'reference_length': 100}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=predictions_1, references=[[ref] for ref in references_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "hLuUU5f37X-i"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': [0.35859304666519165,\n",
       "  0.3157937824726105,\n",
       "  0.35891419649124146,\n",
       "  0.0,\n",
       "  0.36218664050102234,\n",
       "  0.6071540117263794,\n",
       "  0.39615654945373535,\n",
       "  0.40183383226394653,\n",
       "  0.7006238102912903,\n",
       "  0.32159507274627686],\n",
       " 'recall': [0.40656664967536926,\n",
       "  0.3776853680610657,\n",
       "  0.4423854947090149,\n",
       "  0.0,\n",
       "  0.6723802089691162,\n",
       "  0.6155771017074585,\n",
       "  0.6099676489830017,\n",
       "  0.5984358787536621,\n",
       "  0.6191234588623047,\n",
       "  0.7249214053153992],\n",
       " 'f1': [0.381075918674469,\n",
       "  0.3439777195453644,\n",
       "  0.3963022232055664,\n",
       "  0.0,\n",
       "  0.4707808196544647,\n",
       "  0.6113365888595581,\n",
       "  0.48034361004829407,\n",
       "  0.4808139204978943,\n",
       "  0.6573571562767029,\n",
       "  0.4455375075340271],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=predictions_1, references=references_1, model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "j0gnNgp37YNn"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f08224e3904270ba1f2bbca4026f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Експеримент 4: Друг embedding модел (all-distilroberta-v1)\n",
    "embeddings_model_distil = SentenceTransformer('all-distilroberta-v1')\n",
    "document_embeddings_distil = embeddings_model_distil.encode(documents, batch_size=64, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "VCCmd0BX7YcE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"new owner, i heard - but i don't know the details.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = sentences_negative[8]\n",
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-PF2f-ls7vdw"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9584b086b157409383ee36775d8a6115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"great new owner, i heard - but i don't know the details.\",\n",
       " 'the owner knows us and treats us very well!',\n",
       " 'they stock some of the most common parts.',\n",
       " 'the owner is a hoot and the facility is very accommodating.',\n",
       " 'we dropped our rental truck of at this location two weeks ago.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_embedding = embeddings_model_distil.encode(sample_sentence, batch_size=64, show_progress_bar=True)\n",
    "context_results = util.semantic_search(sent_embedding, document_embeddings_distil, top_k=5)\n",
    "doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
    "docs = [documents[d] for d in doc_ids]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "1K9CLnp17vuU"
   },
   "outputs": [],
   "source": [
    "predictions_distil = []\n",
    "references_distil = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "2lqi99f97wC1"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    negative_sent = sentences_negative[i]\n",
    "    positive_sent = sentences_positive[i]\n",
    "\n",
    "    sent_embedding = embeddings_model_distil.encode(negative_sent)\n",
    "    context_results = util.semantic_search(sent_embedding, document_embeddings_distil, top_k=5)\n",
    "    doc_ids = [c['corpus_id'] for c in context_results[0]]\n",
    "    docs = [documents[d] for d in doc_ids]\n",
    "    context = f'Context:\\nExample 1: {docs[0]}\\nExample 2: {docs[1]}\\nExample 3: {docs[2]}\\nExample 4: {docs[3]}\\nExample 5: {docs[4]}'\n",
    "\n",
    "    prompt = f'{context}\\n\\nTransform the following negative sentence to positive: {negative_sent}\\nPositive: '\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
    "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    if 'Positive:' in output:\n",
    "        pred = output.split('Positive:')[-1].strip()\n",
    "    else:\n",
    "        pred = output.split('\\n')[-1].strip()\n",
    "\n",
    "    predictions_distil.append(pred)\n",
    "    references_distil.append(positive_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3f45iVR67wcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.12576964851024927,\n",
       " 'precisions': [0.22093023255813954,\n",
       "  0.13580246913580246,\n",
       "  0.09868421052631579,\n",
       "  0.08450704225352113],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.72,\n",
       " 'translation_length': 172,\n",
       " 'reference_length': 100}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=predictions_distil, references=[[ref] for ref in references_distil])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "sDciBz8H7wqv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.5576872825622559,\n",
       "  0.7167272567749023,\n",
       "  0.5404964685440063,\n",
       "  0.4957411587238312,\n",
       "  0.455392450094223,\n",
       "  0.4574008882045746,\n",
       "  0.4763123393058777,\n",
       "  0.5233611464500427,\n",
       "  0.2370419055223465,\n",
       "  0.4646373391151428],\n",
       " 'recall': [0.4673736095428467,\n",
       "  0.6509063839912415,\n",
       "  0.8947333097457886,\n",
       "  0.7171201705932617,\n",
       "  0.7153955101966858,\n",
       "  0.5507560968399048,\n",
       "  0.6168950200080872,\n",
       "  0.4753214716911316,\n",
       "  0.292397141456604,\n",
       "  0.5394173264503479],\n",
       " 'f1': [0.508551836013794,\n",
       "  0.6822329163551331,\n",
       "  0.6738993525505066,\n",
       "  0.5862269401550293,\n",
       "  0.556523859500885,\n",
       "  0.4997561275959015,\n",
       "  0.5375644564628601,\n",
       "  0.4981858730316162,\n",
       "  0.26182571053504944,\n",
       "  0.4992425739765167],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=predictions_distil, references=references_distil, model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "_XiQkaBa7w8G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"there was no i'm sorry or how did everything come out.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Експеримент 5: Zero-shot (без контекст)\n",
    "sample_sentence = sentences_negative[12]\n",
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "R6X9APm27xN7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Transform the following negative sentence to positive: there was no i'm sorry or how did everything come out.\\nPositive: \""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'Transform the following negative sentence to positive: {sample_sentence}\\nPositive: '\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "lm4GCg0-7xbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Transform the following negative sentence to positive: there was no i'm sorry or how did everything come out.\\nPositive: আসল না অথবা কেউ কি এখানে চুমুল �����\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
    "output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "E1d2Ou4w7yCA"
   },
   "outputs": [],
   "source": [
    "predictions_zero = []\n",
    "references_zero = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "49plRrXR7yRY"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    negative_sent = sentences_negative[i]\n",
    "    positive_sent = sentences_positive[i]\n",
    "\n",
    "    prompt = f'Transform the following negative sentence to positive: {negative_sent}\\nPositive: '\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to('cuda:0')\n",
    "    output_ids = model.generate(tokens.input_ids, max_new_tokens=50)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    if 'Positive:' in output:\n",
    "        pred = output.split('Positive:')[-1].strip()\n",
    "    else:\n",
    "        pred = output.split('\\n')[-1].strip()\n",
    "\n",
    "    predictions_zero.append(pred)\n",
    "    references_zero.append(positive_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "jXuW3hJi7ygI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.009536617286546121,\n",
       " 'precisions': [0.029940119760479042,\n",
       "  0.011077542799597181,\n",
       "  0.006091370558375634,\n",
       "  0.0040941658137154556],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 10.02,\n",
       " 'translation_length': 1002,\n",
       " 'reference_length': 100}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=predictions_zero, references=[[ref] for ref in references_zero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ftWQlpqJ7yuX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': [0.0,\n",
       "  0.4730415344238281,\n",
       "  0.3164166212081909,\n",
       "  0.18399174511432648,\n",
       "  0.7120349407196045,\n",
       "  0.4685872197151184,\n",
       "  0.31048405170440674,\n",
       "  0.3912695050239563,\n",
       "  0.5547829866409302,\n",
       "  0.4000599682331085],\n",
       " 'recall': [0.0,\n",
       "  0.551421046257019,\n",
       "  0.41196054220199585,\n",
       "  0.3349146246910095,\n",
       "  0.8616223335266113,\n",
       "  0.5437687635421753,\n",
       "  0.3629450500011444,\n",
       "  0.574638843536377,\n",
       "  0.7419710159301758,\n",
       "  0.4197489023208618],\n",
       " 'f1': [0.0,\n",
       "  0.5092329978942871,\n",
       "  0.35792213678359985,\n",
       "  0.23750539124011993,\n",
       "  0.7797189354896545,\n",
       "  0.5033863186836243,\n",
       "  0.33467116951942444,\n",
       "  0.46554863452911377,\n",
       "  0.6348665952682495,\n",
       "  0.4096680283546448],\n",
       " 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.47.1)'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore.compute(predictions=predictions_zero, references=references_zero, model_type='microsoft/deberta-xlarge-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "7yHrepOX8OCm"
   },
   "outputs": [],
   "source": [
    "# Во оваа задача резултатите за bleu се подобри од првата задача, бидејќи тука има одговори а не само една буква\n",
    "# RAG со 5 документи даде просечен bertscore од 0.55\n",
    "# RAG со 3 документи даде просечен bertscore од 0.50\n",
    "# RAG со 1 документ даде просечен bertscore од 0.45\n",
    "# RAG со DistilRoberta даде просечен bertscore од 0.40\n",
    "# Zero-shot даде просечен bertscore од 0.45\n",
    "#\n",
    "# Според добиените резултати можеме да заклучиме дека RAG со 1 догумент даде најдобри резултати од сите останати тестови.\n",
    "# RAG со DistilRoberta даде послаб резултат од сите други RAG-ови со 5, 3 и 1 документи\n",
    "# Со помош на zero-shot prompting се добија добри резултати, но не најдобри\n",
    "# Овој пристап не даде најдобри резултати, односно најдобри резултати имавме во задача 1, па во оваа задача \n",
    "# и најлоши имавме во задача 2"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
